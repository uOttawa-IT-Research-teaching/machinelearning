#!/bin/bash

# Count the number of words in a jupyter notebook by discarding output cells and code cells
# Takes one arguemnt: Filename of notebook
count() {
  # shellcheck disable=SC2016
  numwords=$(
    jupyter nbconvert --clear-output --stdout "$1" | \
    jupyter nbconvert --to=markdown --stdin --stdout | \
    sed -e '/```python/,/```/d' | wc -w
  )
}

# Write a single table row for the report
# Takes two arguemnts: Filename of the notebook and name in the table
writetablerow() {
  count "$1"
  echo "| $2 | ${numwords}      |"
  totalwords=$(( totalwords + numwords ))
}

outputdirectory=$(mktemp -d)

# Clone all the notebooks to a temporary directory
for gitrepo in \
  ML_cleaning_and_regression \
  DecisionTrees \
  ML_naive_bayes \
  SVM \
  ML_k-nearest-neightbours \
  ML_Natural_Language_Processing \
  DNN-CNN_Intro
do
  git clone --depth=1 https://github.com/uOttawa-IT-Research-teaching/${gitrepo}.git "${outputdirectory}/${gitrepo}" 2> /dev/null
done

# Write the Markdown report header
cat > words.md <<EOF
# Word count per notebook

Word count for all the Markdown cells can be obtained by cleaning the notebook of output and Python code and converting it to plain text. The generated text will then only have the Markdown and the code blocks. Then count all the words while filtering out the code blocks.

This report was generated by \`countwords.sh\`

# Words


| Notebook                   | Words     |
|----------------------------|----------:|
EOF

# Count the words in each notebook and keep track of the total
totalwords=0

{
  writetablerow "${outputdirectory}/ML_cleaning_and_regression/Bike Weather.ipynb" "ML_cleaning_and_regression";
  writetablerow "${outputdirectory}/DecisionTrees/1-Intro_iris_classification.ipynb" "Decision Trees part 1";
  writetablerow "${outputdirectory}/DecisionTrees/2-intro_iris_RF.ipynb" "Decision Trees part 2";
  writetablerow "${outputdirectory}/DecisionTrees/3-bike_rf_Noise.ipynb" "Decision Trees part 3";
  writetablerow "${outputdirectory}/ML_naive_bayes/bayes.ipynb" "ML_naive_bayes";
  writetablerow "${outputdirectory}/SVM/1-regularization.ipynb" "SVM part 1";
  writetablerow "${outputdirectory}/SVM/2-kernels.ipynb" "SVM part 2";
  writetablerow "${outputdirectory}/SVM/3-deeper_understanding.ipynb" "SVM part 3";
  writetablerow "${outputdirectory}/SVM/4-Noise_Red_RFeduction.ipynb" "SVM part 4";
  writetablerow "${outputdirectory}/ML_k-nearest-neightbours/K-nearest neighbours.ipynb" "K-nearest neighbours"
  writetablerow "${outputdirectory}/ML_Natural_Language_Processing/01-Sentiment Analysis.ipynb" "Natural Language Processing part 1"
  writetablerow "${outputdirectory}/ML_Natural_Language_Processing/02-Unsupervised NLP.ipynb" "Natural Language Processing part 2"
  writetablerow "${outputdirectory}/DNN-CNN_Intro/1 - DNN.ipynb" "Deep and Convolutional Neural Networks part 1"
  writetablerow "${outputdirectory}/DNN-CNN_Intro/2 - DNN_PyTorch.ipynb" "Deep and Convolutional Neural Networks part 2"
  writetablerow "${outputdirectory}/DNN-CNN_Intro/3 - CNN_Concepts.ipynb" "Deep and Convolutional Neural Networks part 3"
} >> words.md

# Clean up the temporary directory
rm -rf "${outputdirectory}"

# Write tht total to the report
{ echo; echo "Total of $totalwords words which with a 10% buffer to account for the ignored code comments becomes $(( totalwords * 11 / 10 ))"; } >> words.md
